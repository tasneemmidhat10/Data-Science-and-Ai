{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30776,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Finetuning-phi3.5-instruct-on-function-calling",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tasneemmidhat10/Data-Science-and-Ai/blob/main/Finetuning_phi3_5_instruct_on_function_calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-10-01T13:09:03.442752Z",
          "iopub.execute_input": "2024-10-01T13:09:03.443048Z",
          "iopub.status.idle": "2024-10-01T13:09:04.377016Z",
          "shell.execute_reply.started": "2024-10-01T13:09:03.443014Z",
          "shell.execute_reply": "2024-10-01T13:09:04.376122Z"
        },
        "trusted": true,
        "id": "tIiN4W5szEEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T13:10:00.961971Z",
          "iopub.execute_input": "2024-10-01T13:10:00.96236Z",
          "iopub.status.idle": "2024-10-01T13:10:01.946488Z",
          "shell.execute_reply.started": "2024-10-01T13:10:00.962325Z",
          "shell.execute_reply": "2024-10-01T13:10:01.945245Z"
        },
        "trusted": true,
        "id": "1JRqqLjQzEEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:52:06.409963Z",
          "iopub.execute_input": "2024-10-01T12:52:06.410487Z",
          "iopub.status.idle": "2024-10-01T12:52:09.480527Z",
          "shell.execute_reply.started": "2024-10-01T12:52:06.410425Z",
          "shell.execute_reply": "2024-10-01T12:52:09.479739Z"
        },
        "trusted": true,
        "id": "QX0kUYykzEEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:52:09.4817Z",
          "iopub.execute_input": "2024-10-01T12:52:09.482271Z",
          "iopub.status.idle": "2024-10-01T12:52:21.986916Z",
          "shell.execute_reply.started": "2024-10-01T12:52:09.482235Z",
          "shell.execute_reply": "2024-10-01T12:52:21.985813Z"
        },
        "trusted": true,
        "id": "oTzhMYetzEEO",
        "outputId": "48323495-ff3f-4705-a916-c7f1bc0d0e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting huggingface\n  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\nDownloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\nInstalling collected packages: huggingface\nSuccessfully installed huggingface-0.0.1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "token = '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'\n",
        "login(token)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:52:21.989757Z",
          "iopub.execute_input": "2024-10-01T12:52:21.990136Z",
          "iopub.status.idle": "2024-10-01T12:52:22.497724Z",
          "shell.execute_reply.started": "2024-10-01T12:52:21.990097Z",
          "shell.execute_reply": "2024-10-01T12:52:22.496806Z"
        },
        "trusted": true,
        "id": "ju40MkAFzEEP",
        "outputId": "27f567eb-f857-4c79-d8da-863ed53d7752"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:52:22.49876Z",
          "iopub.execute_input": "2024-10-01T12:52:22.499071Z",
          "iopub.status.idle": "2024-10-01T12:52:22.565726Z",
          "shell.execute_reply.started": "2024-10-01T12:52:22.499039Z",
          "shell.execute_reply": "2024-10-01T12:52:22.564707Z"
        },
        "trusted": true,
        "id": "gcXwGyZvzEEP",
        "outputId": "fcaaa7a0-5e83-43c2-b187-bf7d89f722cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:52:22.567035Z",
          "iopub.execute_input": "2024-10-01T12:52:22.567598Z",
          "iopub.status.idle": "2024-10-01T12:52:23.649701Z",
          "shell.execute_reply.started": "2024-10-01T12:52:22.56756Z",
          "shell.execute_reply": "2024-10-01T12:52:23.648541Z"
        },
        "trusted": true,
        "id": "zEDkPN1uzEEQ",
        "outputId": "d5f4aa62-aca9-458a-b12c-03817178c212"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Tue Oct  1 12:52:23 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   54C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   50C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U transformers\n",
        "!pip install -q -U peft\n",
        "!pip install -q -U accelerate\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:52:23.651252Z",
          "iopub.execute_input": "2024-10-01T12:52:23.652173Z",
          "iopub.status.idle": "2024-10-01T12:53:49.166929Z",
          "shell.execute_reply.started": "2024-10-01T12:52:23.652131Z",
          "shell.execute_reply": "2024-10-01T12:53:49.165934Z"
        },
        "trusted": true,
        "id": "2jKxE5JYzEER",
        "outputId": "b0fa1c4b-50b8-4315-ffa8-ff50ca00dbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from accelerate import Accelerator\n",
        "accelerator = Accelerator()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:49.168692Z",
          "iopub.execute_input": "2024-10-01T12:53:49.169125Z",
          "iopub.status.idle": "2024-10-01T12:53:49.551854Z",
          "shell.execute_reply.started": "2024-10-01T12:53:49.169066Z",
          "shell.execute_reply": "2024-10-01T12:53:49.551074Z"
        },
        "trusted": true,
        "id": "2-ri6otrzEES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import tqdm\n",
        "\n",
        "ds = load_dataset(\"0xayman/single-function-calls-dataset-28K\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:49.552999Z",
          "iopub.execute_input": "2024-10-01T12:53:49.553787Z",
          "iopub.status.idle": "2024-10-01T12:53:53.3242Z",
          "shell.execute_reply.started": "2024-10-01T12:53:49.553752Z",
          "shell.execute_reply": "2024-10-01T12:53:53.323338Z"
        },
        "trusted": true,
        "id": "IWzOaeqezEET",
        "outputId": "f8c356c9-0aa0-4e56-9dba-84ebe03747f1",
        "colab": {
          "referenced_widgets": [
            "e1708ce854454fa0bc3f2b7ec6a4595a",
            "e8ae844afc5e4ff29989586f2e080fdb",
            "4667cc255de340c6a358ea9b0b450f78"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/402 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1708ce854454fa0bc3f2b7ec6a4595a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "train-00000-of-00001.parquet:   0%|          | 0.00/13.7M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8ae844afc5e4ff29989586f2e080fdb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/28461 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4667cc255de340c6a358ea9b0b450f78"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:53.327642Z",
          "iopub.execute_input": "2024-10-01T12:53:53.328194Z",
          "iopub.status.idle": "2024-10-01T12:53:53.334417Z",
          "shell.execute_reply.started": "2024-10-01T12:53:53.32816Z",
          "shell.execute_reply": "2024-10-01T12:53:53.333504Z"
        },
        "trusted": true,
        "id": "wbDNjqUGzEEU",
        "outputId": "43043115-0308-4901-f480-a68b28dbcf9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'query', 'answers', 'tools'],\n        num_rows: 28461\n    })\n})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:53.335589Z",
          "iopub.execute_input": "2024-10-01T12:53:53.335931Z",
          "iopub.status.idle": "2024-10-01T12:53:53.346843Z",
          "shell.execute_reply.started": "2024-10-01T12:53:53.335899Z",
          "shell.execute_reply": "2024-10-01T12:53:53.345993Z"
        },
        "trusted": true,
        "id": "ACozPH6szEEU",
        "outputId": "0d5d69a5-5b86-4778-e9ab-68630a022b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'id': 1,\n 'query': \"I need to understand the details of the Ethereum blockchain for my cryptocurrency project. Can you fetch the details for 'ethereum'?\",\n 'answers': '[{\"name\": \"web_chain_details\", \"arguments\": {\"chain_slug\": \"ethereum\"}}]',\n 'tools': '[{\"name\": \"peers\", \"description\": \"Retrieves a list of company peers given a stock symbol.\", \"parameters\": {\"symbol\": {\"description\": \"The stock symbol for the company.\", \"type\": \"str\", \"default\": \"\"}}}, {\"name\": \"web_chain_details\", \"description\": \"python\", \"parameters\": {\"chain_slug\": {\"description\": \"The slug identifier for the blockchain (e.g., \\'ethereum\\' for Ethereum mainnet).\", \"type\": \"str\", \"default\": \"ethereum\"}}}]'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import json"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:53.347996Z",
          "iopub.execute_input": "2024-10-01T12:53:53.348275Z",
          "iopub.status.idle": "2024-10-01T12:53:53.354304Z",
          "shell.execute_reply.started": "2024-10-01T12:53:53.348245Z",
          "shell.execute_reply": "2024-10-01T12:53:53.353361Z"
        },
        "trusted": true,
        "id": "6zCettNTzEEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting(sample):\n",
        "    query = sample['query']\n",
        "    answers = sample['answers']\n",
        "    tools = sample['tools']\n",
        "    answers = json.loads(answers)\n",
        "    assert len(answers) == 1, f\"Each query can only be answered by one function, given {answers}\"\n",
        "    answer = answers[0]\n",
        "    prompt = f\"\"\"Your task is to select one of the provided functions to answer the user question.\n",
        "    You should select the most relevant function and extract its arguments from the user's question.\n",
        "    If the user's question doesn't require tool use, answer it from your knowledge. \\n\n",
        "    You can select from the following available tools:\\n\n",
        "    {tools} \\n\n",
        "    You should strictly follow the following tools: \\n\n",
        "    1. Your output should ALWAYS be a valid JSON object.\\n\n",
        "    2. Do not make up information.\\n\n",
        "    3. You cannot use functions that are not provided for you.\\n\n",
        "    4. You should pick up only one function to answer the user question.\\n\n",
        "\n",
        "    Your output json object should have the followig fields:\\n\n",
        "    1. name: the name of the selected function.\\n\n",
        "    2. arguments: an object containing all the function's arguments. the arguments object should contains key-value pairs where is key is the name of the argument and the value is the argument's value extracted from the user query.\\n\n",
        "\n",
        "    Begin!\\n\n",
        "\n",
        "    Question: {query} \\n\n",
        "    Answer: {answer}\n",
        "    \"\"\"\n",
        "    return {'text' : prompt}\n",
        "\n",
        "ds_formatted = ds.map(formatting)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:53.355399Z",
          "iopub.execute_input": "2024-10-01T12:53:53.355707Z",
          "iopub.status.idle": "2024-10-01T12:53:56.605267Z",
          "shell.execute_reply.started": "2024-10-01T12:53:53.355677Z",
          "shell.execute_reply": "2024-10-01T12:53:56.604315Z"
        },
        "trusted": true,
        "id": "vwJut6D9zEEV",
        "outputId": "9602f387-799e-4de4-f9a4-78467de2be69",
        "colab": {
          "referenced_widgets": [
            "630a9c7b374a4b3b8efaafc56b73a5f8"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/28461 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "630a9c7b374a4b3b8efaafc56b73a5f8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_formatted = ds_formatted['train'].train_test_split(test_size=0.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:56.606626Z",
          "iopub.execute_input": "2024-10-01T12:53:56.606947Z",
          "iopub.status.idle": "2024-10-01T12:53:56.645198Z",
          "shell.execute_reply.started": "2024-10-01T12:53:56.606913Z",
          "shell.execute_reply": "2024-10-01T12:53:56.644506Z"
        },
        "trusted": true,
        "id": "tNwvFP9gzEEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LlamaForCausalLM, AutoTokenizer, AutoModelForCausalLM\n",
        "#from llama_recipes.configs import train_config as TRAIN_CONFIG"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:56.646244Z",
          "iopub.execute_input": "2024-10-01T12:53:56.646557Z",
          "iopub.status.idle": "2024-10-01T12:53:57.76292Z",
          "shell.execute_reply.started": "2024-10-01T12:53:56.646525Z",
          "shell.execute_reply": "2024-10-01T12:53:57.762133Z"
        },
        "trusted": true,
        "id": "Za-cAwtlzEEV",
        "outputId": "b8c1d161-122e-441c-ecfc-05fffbb79fbc",
        "colab": {
          "referenced_widgets": [
            "9976237e4b2942aea5011511c32a6451"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "0it [00:00, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9976237e4b2942aea5011511c32a6451"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the model and setting the training hyperparameters and the quantization configurations.\n",
        "Using QLoRA quantization method, the model is loeaded in Normalized float 4 bit (NF4) and the computations are done in BF16."
      ],
      "metadata": {
        "id": "Zcjfd7L-zEEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "config = BitsAndBytesConfig(\n",
        "load_in_4bit = True,\n",
        "bnb_4bit_quant_type = 'nf4',\n",
        "bnb_4bit_use_double_quant = True,\n",
        "bnb_4bit_compute_dtype = torch.bfloat16)\n",
        "model_name = \"microsoft/Phi-3.5-mini-instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=config,\n",
        "    trust_remote_code = True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:53:57.764016Z",
          "iopub.execute_input": "2024-10-01T12:53:57.764454Z",
          "iopub.status.idle": "2024-10-01T12:54:44.628531Z",
          "shell.execute_reply.started": "2024-10-01T12:53:57.764422Z",
          "shell.execute_reply": "2024-10-01T12:54:44.627513Z"
        },
        "trusted": true,
        "id": "6O2EjHbhzEEX",
        "outputId": "977d7e84-1205-47ac-f5e6-b1988cc4fa15",
        "colab": {
          "referenced_widgets": [
            "6a31de022ae5488f8c3ccbf4d2aac6f1",
            "a24e54a0b2774362a0bdbed4e51c071a",
            "5da29d431d2547f0b1f97c570bf28a84",
            "5dfeeeb3f3364a639888493ca6ccb597",
            "0bd9538bbe8f4b0aa0a66474f41b7db3",
            "b406ffe6ccb34add86353d715e71af9e",
            "8306fc9d346640a4a39dd875be9c8f0b",
            "fc0ff38e47074c439ab139805d78278a",
            "d1955f69600c4e3d84a0ff77dee0553c",
            "629b0d8109cc4f9f946a3d3b7f84bbe6",
            "516ce67d19ee4e52ab8d731da3040ce5",
            "837a92ca51934048b105d0f2866a112e",
            "b981444407354c92b5a30d67254e8e90",
            "d97d1de392004b9a9cac56dfd3d63a2d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/3.45k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a31de022ae5488f8c3ccbf4d2aac6f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a24e54a0b2774362a0bdbed4e51c071a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5da29d431d2547f0b1f97c570bf28a84"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3.5-mini-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dfeeeb3f3364a639888493ca6ccb597"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bd9538bbe8f4b0aa0a66474f41b7db3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b406ffe6ccb34add86353d715e71af9e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8306fc9d346640a4a39dd875be9c8f0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc0ff38e47074c439ab139805d78278a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/195 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1955f69600c4e3d84a0ff77dee0553c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/3.98k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "629b0d8109cc4f9f946a3d3b7f84bbe6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "516ce67d19ee4e52ab8d731da3040ce5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "837a92ca51934048b105d0f2866a112e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b981444407354c92b5a30d67254e8e90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d97d1de392004b9a9cac56dfd3d63a2d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:54:44.630025Z",
          "iopub.execute_input": "2024-10-01T12:54:44.630397Z",
          "iopub.status.idle": "2024-10-01T12:54:44.638785Z",
          "shell.execute_reply.started": "2024-10-01T12:54:44.630363Z",
          "shell.execute_reply": "2024-10-01T12:54:44.637895Z"
        },
        "trusted": true,
        "id": "1uBupr4qzEEX",
        "outputId": "0859263e-ef97-4a34-9006-067577a4fe3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import get_peft_model, LoraConfig\n",
        "Qlora_config = LoraConfig(r = 64,\n",
        "                        target_modules = 'all-linear',\n",
        "                        lora_alpha = 128,\n",
        "                        lora_dropout = 0.05,\n",
        "                        task_type = 'CAUSAL_LM')\n",
        "model = get_peft_model(model, Qlora_config)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:54:44.640086Z",
          "iopub.execute_input": "2024-10-01T12:54:44.640387Z",
          "iopub.status.idle": "2024-10-01T12:54:48.595922Z",
          "shell.execute_reply.started": "2024-10-01T12:54:44.640356Z",
          "shell.execute_reply": "2024-10-01T12:54:48.594934Z"
        },
        "trusted": true,
        "id": "0T_puZ9JzEEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install trl\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:54:48.597165Z",
          "iopub.execute_input": "2024-10-01T12:54:48.597987Z",
          "iopub.status.idle": "2024-10-01T12:55:02.07502Z",
          "shell.execute_reply.started": "2024-10-01T12:54:48.597936Z",
          "shell.execute_reply": "2024-10-01T12:55:02.073893Z"
        },
        "trusted": true,
        "id": "y0BE9pKdzEEY",
        "outputId": "12195eb1-1626-4c3b-e7cf-2e247e3d5dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting trl\n  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.4.0)\nRequirement already satisfied: transformers>=4.40.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.45.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.34.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (3.0.0)\nCollecting tyro>=0.5.11 (from trl)\n  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.25.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.40.0->trl) (4.66.4)\nRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.16)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.1)\nCollecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.40.0->trl) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.40.0->trl) (2024.8.30)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\nDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.7.1 trl-0.11.1 tyro-0.8.11\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTConfig, SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "args = TrainingArguments(per_device_train_batch_size=1,\n",
        "                        eval_strategy = 'steps',\n",
        "                        gradient_accumulation_steps = 4,\n",
        "                        learning_rate = 3e-4,\n",
        "                        num_train_epochs = 1,\n",
        "                        warmup_steps = 100,\n",
        "                        fp16 = True,\n",
        "                        output_dir='outputs',\n",
        "                        optim=\"paged_adamw_8bit\")\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = ds_formatted['train'],\n",
        "    eval_dataset = ds_formatted['test'],\n",
        "    tokenizer = tokenizer,\n",
        "    peft_config = Qlora_config,\n",
        "    max_seq_length = 1024,\n",
        "    dataset_text_field = 'text',\n",
        "    args = args\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:55:02.076671Z",
          "iopub.execute_input": "2024-10-01T12:55:02.077022Z",
          "iopub.status.idle": "2024-10-01T12:55:39.800606Z",
          "shell.execute_reply.started": "2024-10-01T12:55:02.076984Z",
          "shell.execute_reply": "2024-10-01T12:55:39.799651Z"
        },
        "trusted": true,
        "id": "Hivo5iJRzEEY",
        "outputId": "b87cf75f-4f1f-4724-981c-e4297a9c6750",
        "colab": {
          "referenced_widgets": [
            "5925d9facd5740bb820926e27859d845",
            "525e4f4eb73a41dc95f7f2671b9d0a98"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/25614 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5925d9facd5740bb820926e27859d845"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/2847 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "525e4f4eb73a41dc95f7f2671b9d0a98"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:55:39.801888Z",
          "iopub.execute_input": "2024-10-01T12:55:39.802275Z",
          "iopub.status.idle": "2024-10-01T12:56:03.292314Z",
          "shell.execute_reply.started": "2024-10-01T12:55:39.80223Z",
          "shell.execute_reply": "2024-10-01T12:56:03.290973Z"
        },
        "trusted": true,
        "id": "RYEWjUKvzEEY",
        "outputId": "37e52ade-c2fa-44dd-a080-f1ce4e68f667"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.18.1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20241001_125549-kddljczp</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface/runs/kddljczp' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface' target=\"_blank\">https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface/runs/kddljczp' target=\"_blank\">https://wandb.ai/tasneemmidhat-university-of-khartoum/huggingface/runs/kddljczp</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='2' max='6403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/6403 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nKeyboardInterrupt\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_to_save = 'Tasneem10/phi3.5-mini-instruct-fc'\n",
        "model.push_to_hub(model_to_save)\n",
        "tokenizer.push_to_hub(model_to_save)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-01T12:56:03.293369Z",
          "iopub.status.idle": "2024-10-01T12:56:03.293734Z",
          "shell.execute_reply.started": "2024-10-01T12:56:03.293559Z",
          "shell.execute_reply": "2024-10-01T12:56:03.293578Z"
        },
        "trusted": true,
        "id": "KGBIwrXvzEEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "relP_bW5zEEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}